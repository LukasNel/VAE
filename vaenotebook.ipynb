{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from pl_bolts.datamodules import CIFAR10DataModule, TinyCIFAR10DataModule\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "import wandb\n",
    "from pl_bolts.transforms.dataset_normalizations import cifar10_normalization\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow, figure, clf\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from argparse import ArgumentParser\n",
    "from pl_bolts.models.autoencoders.components import (\n",
    "    resnet18_decoder,\n",
    "    resnet18_encoder,\n",
    ")\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from numberclassifier import Number_Classifier\n",
    "from tqdm import trange\n",
    "\n",
    "pl.seed_everything(1234)\n",
    "logger = WandbLogger(name=\"VAE\", project=\"VAETesting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/300 [00:04<03:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.02\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.13\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.14\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.10000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.05\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/300 [00:04<01:36,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.08\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.01\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.10000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.07\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.11\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.01\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 16/300 [00:04<00:36,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.08\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.10000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.08999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.01\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.07\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.8\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 24/300 [00:04<00:19, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.01\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.01\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.67999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.52\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.41\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.34\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 28/300 [00:04<00:15, 17.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.72\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.12\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.08999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.06\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.38\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.87\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.05\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 36/300 [00:05<00:11, 23.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 85.11\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.21\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.47\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.34\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.16\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.16\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.46000000000001\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 44/300 [00:05<00:09, 27.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 85.33\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.82\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.91\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.25\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.58\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.78999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.27\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 52/300 [00:05<00:08, 28.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 81.41000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.99\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.13\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.01\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.86\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.95\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 56/300 [00:05<00:08, 29.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.42\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.82000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.02\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.17\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.3\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 60/300 [00:05<00:08, 29.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 85.38\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.92\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.42\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.95\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.22\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.39\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 67/300 [00:06<00:08, 28.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.72\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 83.26\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.15\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.22\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.06\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.39\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 73/300 [00:06<00:07, 28.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 85.95\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.62\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.57000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.71\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.67\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.83\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 80/300 [00:06<00:07, 29.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.89\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.8\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.28999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.98\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.82000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.61\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 88/300 [00:06<00:06, 30.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 85.31\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.57\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.92999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.31\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.03\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.59\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 92/300 [00:06<00:06, 30.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.71000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.28\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.00999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.67\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.11999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 82.32000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.61999999999999\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 100/300 [00:07<00:06, 29.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.62\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.88\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.78\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.99\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.0\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.0\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.81\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 108/300 [00:07<00:06, 29.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.61\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.47\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.89999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.25\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.05000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.1\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.41\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 112/300 [00:07<00:06, 30.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 81.94\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.74\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.42\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 83.66\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.35\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.56\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 120/300 [00:07<00:05, 30.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 85.96000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.74000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.58\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.2\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.27\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.94\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.08\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 124/300 [00:08<00:05, 30.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 81.17999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.42\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.67999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.22\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.52\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 132/300 [00:08<00:05, 29.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 82.83\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 82.22\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.5\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.5\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.58999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.15\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 136/300 [00:08<00:05, 30.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.04\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.97\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.97\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.38\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.89999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 143/300 [00:08<00:05, 28.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.61\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.87\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.65\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.32\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.83\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 150/300 [00:08<00:05, 29.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.67\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.60000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.09\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.48\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.76\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.63\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 157/300 [00:09<00:04, 29.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.36999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.34\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.06\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.92\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.92\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.83\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 161/300 [00:09<00:04, 29.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 84.84\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.14\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.1\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.38\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.67999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 167/300 [00:09<00:04, 28.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.99\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.83\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.84\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.33\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 83.11\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 175/300 [00:09<00:04, 30.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 86.74\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.0\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.56\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.68\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.73\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.08\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.95\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 179/300 [00:09<00:03, 30.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.4\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.1\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.82\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.24000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.41\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.44\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 187/300 [00:10<00:03, 30.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.33\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.46\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.46\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.96000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.08\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 191/300 [00:10<00:03, 30.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 82.07\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.08999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.85000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.57000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.08\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.34\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 199/300 [00:10<00:03, 30.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 86.36\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.42\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.54\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.59\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.52000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.72\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.6\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 203/300 [00:10<00:03, 29.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 86.32\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.28\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 83.46000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.33999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.2\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 210/300 [00:11<00:03, 26.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.77\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.92\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.74\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.08\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.79\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.37\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 217/300 [00:11<00:02, 27.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 85.11999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.76\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.06\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.9\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.08\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.72\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 223/300 [00:11<00:02, 28.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 81.89\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.2\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.32\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.79\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.66\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.75\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 230/300 [00:11<00:02, 28.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 81.35\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.4\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.29\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.6\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.65\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.76\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 233/300 [00:11<00:02, 27.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 81.44\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.22999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.78999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.52\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.19\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 239/300 [00:12<00:02, 25.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 86.24000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.68\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.95\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.99\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.63\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 245/300 [00:12<00:02, 25.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 85.25\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.48\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 82.38\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 83.00999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.00999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.11\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 251/300 [00:12<00:01, 26.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 83.19\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.15\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.04\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.6\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.84\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.44\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 257/300 [00:12<00:01, 26.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 85.11\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.47\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.71\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.86\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.83000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.65\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 263/300 [00:12<00:01, 25.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 81.96\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.02\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.53999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.84\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.77\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 266/300 [00:13<00:01, 25.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.25999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.48\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.07000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.99\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.24000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 272/300 [00:13<00:01, 25.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.47\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.05000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 84.86\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.61\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 278/300 [00:13<00:00, 25.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 81.08999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.58\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.01\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.71000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.97\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 281/300 [00:13<00:00, 25.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 81.25\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.85000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.53999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.48\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.8\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 287/300 [00:13<00:00, 25.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 80.12\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.82000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.6\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.10000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.47\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 86.24000000000001\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 293/300 [00:14<00:00, 24.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 85.94000000000001\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 83.23\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 80.42\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.16\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.57000000000001\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 299/300 [00:14<00:00, 23.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 85.64\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 83.39999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 81.17999999999999\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.36\n",
      "combo torch.Size([15910])\n",
      "reconst test_accuracy 85.02\n",
      "combo torch.Size([15910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:14<00:00, 20.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconst test_accuracy 81.86\n",
      "modelparams 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2400x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tensor_transform = transforms.ToTensor()\n",
    "mnist_trainset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=tensor_transform\n",
    ")\n",
    "mnist_testset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=tensor_transform\n",
    ")\n",
    "maxtrain = torch.max(mnist_trainset.data)\n",
    "maxtest = torch.max(mnist_testset.data)\n",
    "# load into torch datasets\n",
    "# To speed up training, we subset to 10,000 (instead of 60,000) images. You can change this if you want better performance.\n",
    "train_dataset = torch.utils.data.TensorDataset(mnist_trainset.data.to(\n",
    "    dtype=torch.float32)[:10000]/maxtrain, mnist_trainset.targets.to(dtype=torch.long)[:10000])\n",
    "test_dataset = torch.utils.data.TensorDataset(mnist_testset.data.to(\n",
    "    dtype=torch.float32)/maxtest, mnist_testset.targets.to(dtype=torch.long))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_accuracy(output, targets):\n",
    "    output = output.detach()  # this removes the gradients associated with the tensor\n",
    "    predicted = output.argmax(-1)\n",
    "    correct = (predicted == targets).sum().item()\n",
    "    accuracy = correct / output.size(0) * 100\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "figure(figsize=(8, 3), dpi=300)\n",
    "\n",
    "\n",
    "class Number_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(784, 20)\n",
    "        # These are PyTorch's predefined layers. Each is a class. In the \"init\" function, we just initialize and instantiate the classes, creating objects (that behave like functions)\n",
    "        self.layer2 = nn.Linear(20, 10)\n",
    "        self.nonlin = nn.ReLU()\n",
    "        # self.softmax = nn.Softmax() # Converts numbers into probabilities\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)  # Composing the functions we created below\n",
    "        x = self.nonlin(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_test_accuracy(x_hat):\n",
    "    weight_1_matrix, weight_2_matrix, bias_1_matrix, bias_2_matrix = torch.split(\n",
    "                x_hat, (20 * 784, 10 * 20, 20, 10))\n",
    "    classifier = Number_Classifier()\n",
    "    classifier.to(device)\n",
    "    # train_ep_pred = classifier(mnist_trainset.data.to(dtype=torch.float32).reshape(-1,28*28).to(device))\n",
    "    # test_ep_pred = classifier(mnist_testset.data.to(dtype=torch.float32).reshape(-1,28*28).to(device))\n",
    "\n",
    "    # train_accuracy = get_accuracy(train_ep_pred.cpu(), mnist_trainset.targets.to(dtype=torch.long))\n",
    "    # test_accuracy = get_accuracy(test_ep_pred.cpu(), mnist_testset.targets.to(dtype=torch.long))\n",
    "    # print(\"reconst test_accuracy\", test_accuracy, \"reconst train_accuracy\", train_accuracy)\n",
    "    classifier_load = {}\n",
    "    classifier_load[\"layer1.weight\"] = weight_1_matrix.reshape((20,784))\n",
    "    classifier_load[\"layer2.weight\"] = weight_2_matrix.reshape((10,20))\n",
    "    classifier_load[\"layer1.bias\"] = bias_1_matrix\n",
    "    classifier_load[\"layer2.bias\"] = bias_2_matrix\n",
    "\n",
    "    classifier.load_state_dict(classifier_load, strict=True)\n",
    "    test_ep_pred = classifier(mnist_testset.data.to(dtype=torch.float32).reshape(-1,28*28).to(device))\n",
    "\n",
    "    test_accuracy = get_accuracy(test_ep_pred.cpu(), mnist_testset.targets.to(dtype=torch.long))\n",
    "    return test_accuracy\n",
    "\n",
    "\n",
    "model_params = []\n",
    "\n",
    "for i in trange(300):\n",
    "    classifier_load = torch.load(\n",
    "        \"new_data/model_{}.pth\".format(i+1), map_location='cuda')\n",
    "    # print(classifier_load)\n",
    "    weight_1_matrix = classifier_load[\"layer1.weight\"]\n",
    "    weight_2_matrix = classifier_load[\"layer2.weight\"]\n",
    "    bias_1_matrix = classifier_load[\"layer1.bias\"]\n",
    "    bias_2_matrix = classifier_load[\"layer2.bias\"]\n",
    "   \n",
    "    \n",
    "    weight_1_matrix = weight_1_matrix.reshape(20*784)\n",
    "    weight_2_matrix = weight_2_matrix.reshape(200)\n",
    "\n",
    "    \n",
    "\n",
    "    #bias_1_matrix = bias_1_matrix.reshpae(20)\n",
    "    #bias_2_matrix = bias_2_matrix.reshpae(19)\n",
    "    combo = torch.cat((weight_1_matrix, weight_2_matrix,\n",
    "                      bias_1_matrix, bias_2_matrix))\n",
    "    print(\"combo\", combo.shape)\n",
    "\n",
    "    model_params.append(combo.reshape(1,15910))\n",
    "    \n",
    "    print(\"reconst test_accuracy\", get_test_accuracy(combo))\n",
    "    del weight_1_matrix\n",
    "    del weight_2_matrix\n",
    "    del bias_1_matrix\n",
    "    del bias_2_matrix\n",
    "    del classifier_load\n",
    "    # del combo\n",
    "print(\"modelparams\", len(model_params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, weights, transform=None, target_transform=None):\n",
    "        self.weight_data = weights\n",
    "        self.img_labels = []  # pd.read_csv(annotations_file)\n",
    "        indices = []\n",
    "        for i in range(len(weights)):\n",
    "            self.img_labels.append(0)\n",
    "            indices.append(i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.weight_data[idx].to(device)\n",
    "        label = (idx//10) % 10\n",
    "        return image, torch.tensor(label).to(device)\n",
    "\n",
    "\n",
    "\n",
    "weights_data_set = WeightsDataset(model_params)\n",
    "\n",
    "weights_data_loader = torch.utils.data.DataLoader(\n",
    "    weights_data_set, batch_size=20, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageSampler(pl.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.img_size = None\n",
    "        self.num_preds = 16\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module, outputs):\n",
    "        clf()\n",
    "        # Z COMES FROM NORMAL(0, 1)\n",
    "        rand_v = torch.randn(\n",
    "            (self.num_preds, pl_module.hparams.latent_dim), device=pl_module.device)\n",
    "        p = torch.distributions.Normal(\n",
    "            torch.zeros_like(rand_v), torch.ones_like(rand_v))\n",
    "        z = p.rsample()\n",
    "\n",
    "        # SAMPLE IMAGES\n",
    "        with torch.no_grad():\n",
    "            pred = pl_module.decoder(z.to(pl_module.device)).cpu()\n",
    "        print(\"pred\", pred.shape)\n",
    "        pred = pred.reshape((16, 2*43, 5*37))\n",
    "        # UNDO DATA NORMALIZATION\n",
    "        normalize = cifar10_normalization()\n",
    "        mean, std = np.array(normalize.mean), np.array(normalize.std)\n",
    "        # img = make_grid(pred).numpy() #* std + mean\n",
    "        samples = [wandb.Image(img) for img in pred]\n",
    "        # PLOT IMAGES\n",
    "        wandb.log({\"images\": samples})\n",
    "\n",
    "\n",
    "\n",
    "    # reconstruction loss\n",
    "\n",
    "\n",
    "class NumberSampler(pl.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.img_size = None\n",
    "        self.num_preds = 16\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module, outputs):\n",
    "        clf()\n",
    "        # Z COMES FROM NORMAL(0, 1)\n",
    "        rand_v = torch.randn(\n",
    "            (self.num_preds, pl_module.hparams.latent_dim), device=pl_module.device)\n",
    "        p = torch.distributions.Normal(\n",
    "            torch.zeros_like(rand_v), torch.ones_like(rand_v))\n",
    "        z = p.rsample()\n",
    "\n",
    "        # SAMPLE IMAGES\n",
    "        with torch.no_grad():\n",
    "            pred = pl_module.decoder(z.to(pl_module.device)).cpu()\n",
    "        test_accuracy_out = []\n",
    "        for combo in pred:\n",
    "            print(combo.shape)\n",
    "            test_accuracy = get_test_accuracy(combo)\n",
    "            print(\"add weights test_accuracy\", test_accuracy)\n",
    "            test_accuracy_out.append(test_accuracy)\n",
    "\n",
    "        \n",
    "        sumnp = pred.numpy().sum()\n",
    "        print(\"sumnp\", sumnp)\n",
    "        avgtest = np.average(np.array(test_accuracy_out))\n",
    "        print(\"avg test_accuracy\", avgtest)\n",
    "        wandb.log({\"test_accuracy\": avgtest})\n",
    "        wandb.log({\"sumofweights\": sumnp})\n",
    "\n",
    "\n",
    "# For the afficianados: the (nn.Module) subclasses PyTorch's neural network superclass, which, when initialized below...\n",
    "class Encode(nn.Module):\n",
    "    def __init__(self, input_height):\n",
    "        # <--- does a bunch of janitorial work to make our network easier to use. For example, once our network is initialized, calling IttyBittyNetwork(data) passes the data into forward.\n",
    "        super().__init__()\n",
    "        self.input_height = input_height\n",
    "        self.encoding_model = nn.Sequential(\n",
    "            nn.Linear(input_height, 400),\n",
    "            nn.ReLU(),\n",
    "            # Initializing the classes adds their free variables to our network's list of parameters to update via gradient descent.\n",
    "            nn.Linear(400, 200),\n",
    "            nn.ReLU(),\n",
    "            # Initializing the classes adds their free variables to our network's list of parameters to update via gradient descent.\n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(100, 50),  # Note this ends with a 10 dimensional output.\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(50, 40),\n",
    "        )\n",
    "        # self.softmax = nn.Softmax() # Converts numbers into probabilities\n",
    "\n",
    "    def encode(self, x):\n",
    "        # print(\"shape\", x.shape)\n",
    "        # x = torch.reshape(x, (-1, self.input_height * self.input_height * 3))\n",
    "        x = self.encoding_model(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.encode(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "# For the afficianados: the (nn.Module) subclasses PyTorch's neural network superclass, which, when initialized below...\n",
    "class Decode(nn.Module):\n",
    "    def __init__(self, input_height):\n",
    "        # <--- does a bunch of janitorial work to make our network easier to use. For example, once our network is initialized, calling IttyBittyNetwork(data) passes the data into forward.\n",
    "        super().__init__()\n",
    "        self.nonlin = nn.ReLU()\n",
    "        # self.softmax = nn.Softmax() # Converts numbers into probabilities\n",
    "        self.decoding_model = nn.Sequential(\n",
    "            # nn.Linear(20, 50),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(50, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, input_height),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.sig = nn.ReLU()\n",
    "        self.input_height = input_height\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = self.decoding_model(x)\n",
    "        # x = torch.reshape(x, (-1, 3, self.input_height, self.input_height))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decode(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class VAE(pl.LightningModule):\n",
    "    def __init__(self, enc_out_dim=100, latent_dim=50, input_height=15910):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        device = torch.device(\"cpu\")\n",
    "        self.encoder = Encode(input_height)\n",
    "        self.encoder.to(device)\n",
    "        self.decoder = Decode(input_height)\n",
    "        self.decoder.to(device)\n",
    "        print(\"cuda\", device)\n",
    "        # encoder, decoder\n",
    "        # self.encoder = resnet18_encoder(False, False)\n",
    "        # self.decoder = resnet18_decoder(\n",
    "        #     latent_dim=latent_dim,\n",
    "        #     input_height=input_height,\n",
    "        #     first_conv=False,\n",
    "        #     maxpool1=False\n",
    "        # )\n",
    "\n",
    "        # distribution parameters\n",
    "        self.fc_mu = nn.Linear(enc_out_dim, latent_dim)\n",
    "        self.fc_mu.to(device)\n",
    "        self.fc_var = nn.Linear(enc_out_dim, latent_dim)\n",
    "        self.fc_var.to(device)\n",
    "\n",
    "        # for the gaussian likelihood\n",
    "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "        self.log_scale.to(device)\n",
    "        device\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "    def gaussian_likelihood(self, x_hat, logscale, x):\n",
    "        scale = torch.exp(logscale)\n",
    "        mean = x_hat\n",
    "        mean.to(device)\n",
    "        scale.to(device)\n",
    "\n",
    "        dist = torch.distributions.Normal(mean, scale)\n",
    "        x.to(device)\n",
    "        # measure prob of seeing image under p(x|z)\n",
    "        log_pxz = dist.log_prob(x)\n",
    "        # print(\"log_pxz\", log_pxz.shape)\n",
    "        return log_pxz.sum(dim=(1))\n",
    "\n",
    "    def kl_divergence(self, z, mu, std):\n",
    "        # --------------------------\n",
    "        # Monte carlo KL divergence\n",
    "        # --------------------------\n",
    "        # 1. define the first two probabilities (in this case Normal for both)\n",
    "        p = torch.distributions.Normal(\n",
    "            torch.zeros_like(mu), torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "        # 2. get the probabilities from the equation\n",
    "        log_qzx = q.log_prob(z)\n",
    "        log_pz = p.log_prob(z)\n",
    "\n",
    "        # kl\n",
    "        kl = (log_qzx - log_pz)\n",
    "        kl = kl.sum(-1)\n",
    "        return kl\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x.to(device)\n",
    "\n",
    "        # encode x to get the mu and variance parameters\n",
    "        x_encoded = self.encoder(x)\n",
    "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "\n",
    "        # sample z from q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "\n",
    "        # decoded\n",
    "        x_hat = self.decoder(z)\n",
    "        x_hat.to(device)\n",
    "        for i in range(len(batch)):\n",
    "            print(\"get_test_accuracy\", get_test_accuracy(x_hat[i]), get_test_accuracy(x[i]))\n",
    "            xhatavg, xavg, xratio = (np.average(x_hat[i].cpu().detach().numpy()) ,np.average(x[i].cpu().detach().numpy()),  np.sum(x_hat[i].cpu().detach().numpy())/np.sum(x[i].cpu().detach().numpy()))\n",
    "            xhatstd, xstd = (np.std(x_hat[i].cpu().detach().numpy()) ,np.std(x[i].cpu().detach().numpy()))\n",
    "            \n",
    "            print(\"sumnp\",xhatavg, xavg, xratio )\n",
    "            print(\"sumnp\",xhatstd, xstd )\n",
    "            wandb.log({\n",
    "                'xhatavg': xhatavg,\n",
    "                'xavg': xavg,\n",
    "                'xratio': xratio,\n",
    "                'xstd': xstd,\n",
    "                'xhatstd': xhatstd,\n",
    "            })\n",
    "        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
    "        \n",
    "\n",
    "        # kl\n",
    "        kl = self.kl_divergence(z, mu, std)\n",
    "\n",
    "        # elbo\n",
    "        elbo = (kl - recon_loss)\n",
    "        elbo = elbo.mean()\n",
    "\n",
    "        wandb.log({\n",
    "            'elbo': elbo,\n",
    "            'kl': kl.mean(),\n",
    "            'recon_loss': recon_loss.mean(),\n",
    "            'reconstruction': recon_loss.mean(),\n",
    "            'kl': kl.mean(),\n",
    "        })\n",
    "\n",
    "        return elbo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlukas-nel\u001b[0m (\u001b[33m2084experiments\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: c:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py 127 experiment\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m vae \u001b[38;5;241m=\u001b[39m VAE()\n\u001b[0;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(gpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, logger\u001b[38;5;241m=\u001b[39mlogger,\n\u001b[0;32m      6\u001b[0m                         max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[sampler],auto_lr_find\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_data_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:445\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[39m# TRAIN\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mon_fit_start\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 445\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator_backend\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    446\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator_backend\u001b[39m.\u001b[39mteardown()\n\u001b[0;32m    448\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# hook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\accelerators\\gpu_accelerator.py:61\u001b[0m, in \u001b[0;36mGPUAccelerator.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     58\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[0;32m     60\u001b[0m \u001b[39m# set up training routine\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain_loop\u001b[39m.\u001b[39;49msetup_training(model)\n\u001b[0;32m     63\u001b[0m \u001b[39m# train or test\u001b[39;00m\n\u001b[0;32m     64\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_or_test()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py:144\u001b[0m, in \u001b[0;36mTrainLoop.setup_training\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39m# log hyper-parameters\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlogger \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39m# save exp to get started (this is where the first experiment logs are written)\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mlogger\u001b[39m.\u001b[39;49mlog_hyperparams(ref_model\u001b[39m.\u001b[39;49mhparams_initial)\n\u001b[0;32m    145\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mlog_graph(ref_model)\n\u001b[0;32m    146\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39msave()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:35\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m rank_zero_only\u001b[39m.\u001b[39mrank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:143\u001b[0m, in \u001b[0;36mWandbLogger.log_hyperparams\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    141\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flatten_dict(params)\n\u001b[0;32m    142\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sanitize_callable_params(params)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperiment\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mupdate(params, allow_val_change\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\loggers\\base.py:483\u001b[0m, in \u001b[0;36mrank_zero_experiment.<locals>.experiment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[39m@rank_zero_only\u001b[39m\n\u001b[0;32m    481\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_experiment\u001b[39m():\n\u001b[0;32m    482\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 483\u001b[0m \u001b[39mreturn\u001b[39;00m get_experiment() \u001b[39mor\u001b[39;00m DummyExperiment()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:35\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m rank_zero_only\u001b[39m.\u001b[39mrank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\loggers\\base.py:482\u001b[0m, in \u001b[0;36mrank_zero_experiment.<locals>.experiment.<locals>.get_experiment\u001b[1;34m()\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[39m@rank_zero_only\u001b[39m\n\u001b[0;32m    481\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_experiment\u001b[39m():\n\u001b[1;32m--> 482\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:127\u001b[0m, in \u001b[0;36mWandbLogger.experiment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offline:\n\u001b[0;32m    126\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mWANDB_MODE\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdryrun\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experiment \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39minit(\n\u001b[0;32m    128\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, \u001b[39mdir\u001b[39m\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_dir, project\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_project, anonymous\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_anonymous,\n\u001b[0;32m    129\u001b[0m     reinit\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39mid\u001b[39m\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id, resume\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mallow\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs)\n\u001b[0;32m    130\u001b[0m \u001b[39m# save checkpoints in wandb dir to upload on W&B servers\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_model:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1100\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[39massert\u001b[39;00m logger\n\u001b[0;32m   1099\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39minterrupted\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39me)\n\u001b[1;32m-> 1100\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m   1101\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1102\u001b[0m     error_seen \u001b[39m=\u001b[39m e\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1078\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1076\u001b[0m except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n\u001b[0;32m   1077\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1078\u001b[0m     run \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39;49minit()\n\u001b[0;32m   1079\u001b[0m     except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n\u001b[0;32m   1080\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:697\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    693\u001b[0m logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    694\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcommunicating run to backend with \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39minit_timeout\u001b[39m}\u001b[39;00m\u001b[39m second timeout\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    695\u001b[0m )\n\u001b[0;32m    696\u001b[0m handle \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39minterface\u001b[39m.\u001b[39mdeliver_run(run)\n\u001b[1;32m--> 697\u001b[0m result \u001b[39m=\u001b[39m handle\u001b[39m.\u001b[39;49mwait(\n\u001b[0;32m    698\u001b[0m     timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings\u001b[39m.\u001b[39;49minit_timeout, on_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_on_progress_init\n\u001b[0;32m    699\u001b[0m )\n\u001b[0;32m    700\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[0;32m    701\u001b[0m     run_result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mrun_result\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py:261\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[1;34m(self, timeout, on_probe, on_progress, release)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interface\u001b[39m.\u001b[39m_transport_keepalive_failed():\n\u001b[0;32m    259\u001b[0m         \u001b[39mraise\u001b[39;00m MailboxError(\u001b[39m\"\u001b[39m\u001b[39mtransport failed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 261\u001b[0m found \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_slot\u001b[39m.\u001b[39;49m_get_and_clear(timeout\u001b[39m=\u001b[39;49mwait_timeout)\n\u001b[0;32m    262\u001b[0m \u001b[39mif\u001b[39;00m found:\n\u001b[0;32m    263\u001b[0m     \u001b[39m# Always update progress to 100% when done\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     \u001b[39mif\u001b[39;00m on_progress \u001b[39mand\u001b[39;00m progress_handle \u001b[39mand\u001b[39;00m progress_sent:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py:118\u001b[0m, in \u001b[0;36m_MailboxSlot._get_and_clear\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_and_clear\u001b[39m(\u001b[39mself\u001b[39m, timeout: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[pb\u001b[39m.\u001b[39mResult]:\n\u001b[0;32m    117\u001b[0m     found \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait(timeout\u001b[39m=\u001b[39;49mtimeout):\n\u001b[0;32m    119\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    120\u001b[0m             found \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py:114\u001b[0m, in \u001b[0;36m_MailboxSlot._wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wait\u001b[39m(\u001b[39mself\u001b[39m, timeout: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout\u001b[39m=\u001b[39;49mtimeout)\n",
      "File \u001b[1;32mC:\\Python39\\lib\\threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    572\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    573\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 574\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mC:\\Python39\\lib\\threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[0;32m    317\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sampler = ImageSampler()\n",
    "numsampler = NumberSampler()\n",
    "\n",
    "vae = VAE()\n",
    "trainer = pl.Trainer(gpus=1, logger=logger,\n",
    "                        max_epochs=300, callbacks=[sampler],auto_lr_find=True)\n",
    "trainer.fit(vae, weights_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type                | Params\n",
      "--------------------------------------------------\n",
      "0 | diffmodel | Unet1D              | 14.9 M\n",
      "1 | diffusion | GaussianDiffusion1D | 14.9 M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "train\n",
      "train\n",
      "Epoch 0:   0%|          | 0/15 [00:00<?, ?it/s] "
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 78.00 MiB (GPU 0; 4.00 GiB total capacity; 3.48 GiB already allocated; 0 bytes free; 3.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 92\u001b[0m\n\u001b[0;32m     89\u001b[0m dmmod \u001b[38;5;241m=\u001b[39m DiffModel()\n\u001b[0;32m     90\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(gpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, logger\u001b[38;5;241m=\u001b[39mlogger,\n\u001b[0;32m     91\u001b[0m                         max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[sampler],auto_lr_find\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 92\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdmmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_data_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# loss = diffusion(training_images)\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:445\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[39m# TRAIN\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mon_fit_start\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 445\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator_backend\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    446\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator_backend\u001b[39m.\u001b[39mteardown()\n\u001b[0;32m    448\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# hook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\accelerators\\gpu_accelerator.py:67\u001b[0m, in \u001b[0;36mGPUAccelerator.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[39m# train or test\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_or_test()\n\u001b[0;32m     68\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py:67\u001b[0m, in \u001b[0;36mAccelerator.train_or_test\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mrun_test()\n\u001b[0;32m     66\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 67\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     68\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:494\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loop\u001b[39m.\u001b[39mon_train_epoch_start(epoch)\n\u001b[0;32m    493\u001b[0m \u001b[39m# run train epoch\u001b[39;00m\n\u001b[1;32m--> 494\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_loop\u001b[39m.\u001b[39;49mrun_training_epoch()\n\u001b[0;32m    496\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_steps \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_steps \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_step:\n\u001b[0;32m    497\u001b[0m \n\u001b[0;32m    498\u001b[0m     \u001b[39m# hook\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loop\u001b[39m.\u001b[39mon_train_end()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py:561\u001b[0m, in \u001b[0;36mTrainLoop.run_training_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mbatch_idx \u001b[39m=\u001b[39m batch_idx\n\u001b[0;32m    558\u001b[0m \u001b[39m# ------------------------------------\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[39m# TRAINING_STEP + TRAINING_STEP_END\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[39m# ------------------------------------\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_training_batch(batch, batch_idx, dataloader_idx)\n\u001b[0;32m    563\u001b[0m \u001b[39m# when returning -1 from train_step, we end epoch early\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39mif\u001b[39;00m batch_output\u001b[39m.\u001b[39msignal \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py:728\u001b[0m, in \u001b[0;36mTrainLoop.run_training_batch\u001b[1;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m result\u001b[39m.\u001b[39mloss\n\u001b[0;32m    727\u001b[0m     \u001b[39m# optimizer step\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer_step(optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\n\u001b[0;32m    730\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_curr_step_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(split_batch, batch_idx, opt_idx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhiddens)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py:469\u001b[0m, in \u001b[0;36mTrainLoop.optimizer_step\u001b[1;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure, *args, **kwargs)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\u001b[39mself\u001b[39m, optimizer, opt_idx, batch_idx, train_step_and_backward_closure, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    467\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39moptimizer_step\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    468\u001b[0m         \u001b[39m# optimizer step lightningModule hook\u001b[39;00m\n\u001b[1;32m--> 469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39maccelerator_backend\u001b[39m.\u001b[39moptimizer_step(\n\u001b[0;32m    470\u001b[0m             optimizer, batch_idx, opt_idx, train_step_and_backward_closure, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    471\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py:115\u001b[0m, in \u001b[0;36mAccelerator.optimizer_step\u001b[1;34m(self, optimizer, batch_idx, opt_idx, lambda_closure, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[0;32m    111\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnative PyTorch amp and lbfgs are not compatible.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    112\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m To request, please file a Github issue in PyTorch and tag @mcarilli\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m model_ref\u001b[39m.\u001b[39moptimizer_step(\n\u001b[0;32m    116\u001b[0m     epoch\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mcurrent_epoch,\n\u001b[0;32m    117\u001b[0m     batch_idx\u001b[39m=\u001b[39mbatch_idx,\n\u001b[0;32m    118\u001b[0m     optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[0;32m    119\u001b[0m     optimizer_idx\u001b[39m=\u001b[39mopt_idx,\n\u001b[0;32m    120\u001b[0m     optimizer_closure\u001b[39m=\u001b[39mlambda_closure,\n\u001b[0;32m    121\u001b[0m     on_tpu\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,  \u001b[39m# TPUAccelerator class sets this as True\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     using_native_amp\u001b[39m=\u001b[39musing_native_amp,\n\u001b[0;32m    123\u001b[0m     using_lbfgs\u001b[39m=\u001b[39mis_lbfgs,\n\u001b[0;32m    124\u001b[0m     \u001b[39m*\u001b[39margs,\n\u001b[0;32m    125\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    126\u001b[0m )\n\u001b[0;32m    128\u001b[0m \u001b[39m# scale when native amp\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m automatic_optimization \u001b[39mand\u001b[39;00m using_native_amp:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\core\\lightning.py:1380\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1378\u001b[0m     optimizer\u001b[39m.\u001b[39mstep(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1380\u001b[0m     optimizer\u001b[39m.\u001b[39mstep(closure\u001b[39m=\u001b[39moptimizer_closure, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\torch\\optim\\adam.py:183\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[1;32m--> 183\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    185\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[0;32m    186\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py:718\u001b[0m, in \u001b[0;36mTrainLoop.run_training_batch.<locals>.train_step_and_backward_closure\u001b[1;34m()\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step_and_backward_closure\u001b[39m():\n\u001b[1;32m--> 718\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step_and_backward(\n\u001b[0;32m    719\u001b[0m         split_batch,\n\u001b[0;32m    720\u001b[0m         batch_idx,\n\u001b[0;32m    721\u001b[0m         opt_idx,\n\u001b[0;32m    722\u001b[0m         optimizer,\n\u001b[0;32m    723\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mhiddens\n\u001b[0;32m    724\u001b[0m     )\n\u001b[0;32m    725\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py:813\u001b[0m, in \u001b[0;36mTrainLoop.training_step_and_backward\u001b[1;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[39mwrap the forward step in a closure so second order methods work\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[39m# lightning module hook\u001b[39;00m\n\u001b[1;32m--> 813\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(split_batch, batch_idx, opt_idx, hiddens)\n\u001b[0;32m    814\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_curr_step_result \u001b[39m=\u001b[39m result\n\u001b[0;32m    816\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py:320\u001b[0m, in \u001b[0;36mTrainLoop.training_step\u001b[1;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mmodel_forward\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    319\u001b[0m     args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_train_args(split_batch, batch_idx, opt_idx, hiddens)\n\u001b[1;32m--> 320\u001b[0m     training_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49maccelerator_backend\u001b[39m.\u001b[39;49mtraining_step(args)\n\u001b[0;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_training_step_output(training_step_output)\n\u001b[0;32m    323\u001b[0m     training_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mcall_hook(\u001b[39m\"\u001b[39m\u001b[39mtraining_step_end\u001b[39m\u001b[39m\"\u001b[39m, training_step_output)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\accelerators\\gpu_accelerator.py:75\u001b[0m, in \u001b[0;36mGPUAccelerator.training_step\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m     73\u001b[0m         output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__training_step(args)\n\u001b[0;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__training_step(args)\n\u001b[0;32m     77\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\pytorch_lightning\\accelerators\\gpu_accelerator.py:83\u001b[0m, in \u001b[0;36mGPUAccelerator.__training_step\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m     81\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_device(batch)\n\u001b[0;32m     82\u001b[0m args[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m batch\n\u001b[1;32m---> 83\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtraining_step(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m     84\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "Cell \u001b[1;32mIn[8], line 32\u001b[0m, in \u001b[0;36mDiffModel.training_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     29\u001b[0m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m x  \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m15910\u001b[39m))\n\u001b[1;32m---> 32\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss,\n\u001b[0;32m     35\u001b[0m })\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\denoising_diffusion_pytorch\\denoising_diffusion_pytorch_1d.py:695\u001b[0m, in \u001b[0;36mGaussianDiffusion1D.forward\u001b[1;34m(self, img, *args, **kwargs)\u001b[0m\n\u001b[0;32m    692\u001b[0m t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps, (b,), device\u001b[39m=\u001b[39mdevice)\u001b[39m.\u001b[39mlong()\n\u001b[0;32m    694\u001b[0m img \u001b[39m=\u001b[39m normalize_to_neg_one_to_one(img)\n\u001b[1;32m--> 695\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp_losses(img, t, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\denoising_diffusion_pytorch\\denoising_diffusion_pytorch_1d.py:671\u001b[0m, in \u001b[0;36mGaussianDiffusion1D.p_losses\u001b[1;34m(self, x_start, t, noise)\u001b[0m\n\u001b[0;32m    667\u001b[0m         x_self_cond\u001b[39m.\u001b[39mdetach_()\n\u001b[0;32m    669\u001b[0m \u001b[39m# predict and take gradient step\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m model_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x, t, x_self_cond)\n\u001b[0;32m    673\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpred_noise\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    674\u001b[0m     target \u001b[39m=\u001b[39m noise\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\denoising_diffusion_pytorch\\denoising_diffusion_pytorch_1d.py:344\u001b[0m, in \u001b[0;36mUnet1D.forward\u001b[1;34m(self, x, time, x_self_cond)\u001b[0m\n\u001b[0;32m    341\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((x_self_cond, x), dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m    343\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_conv(x)\n\u001b[1;32m--> 344\u001b[0m r \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mclone()\n\u001b[0;32m    346\u001b[0m t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_mlp(time)\n\u001b[0;32m    348\u001b[0m h \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 78.00 MiB (GPU 0; 4.00 GiB total capacity; 3.48 GiB already allocated; 0 bytes free; 3.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from denoising_diffusion_pytorch import Unet1D, GaussianDiffusion1D\n",
    "class DiffModel(pl.LightningModule):\n",
    "    def __init__(self,  input_height=15910):\n",
    "        super().__init__()\n",
    "        self.diffmodel = Unet1D(\n",
    "            dim = 64,\n",
    "            dim_mults = (1, 2, 4, 8),\n",
    "            channels = 1\n",
    "        )\n",
    "\n",
    "        self.diffusion = GaussianDiffusion1D(\n",
    "            self.diffmodel,\n",
    "            seq_length = input_height,\n",
    "            timesteps = 100,\n",
    "            objective = 'pred_v'\n",
    "        )\n",
    "        print(\"loss\", )\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x.to(device)\n",
    "        x  = x.reshape((-1,1,15910))\n",
    "        \n",
    "        loss = self.diffusion(x)\n",
    "        wandb.log({\n",
    "            'loss': loss,\n",
    "        })\n",
    "        print(\"loss\", loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "# model = Unet1D(\n",
    "#     dim = 64,\n",
    "#     dim_mults = (1, 2, 4, 8),\n",
    "#     channels = 1\n",
    "# ).cuda()\n",
    "\n",
    "# diffusion = GaussianDiffusion1D(\n",
    "#     model.to(device),\n",
    "#     seq_length = 15910,\n",
    "#     timesteps = 10,\n",
    "#     objective = 'pred_v'\n",
    "# ).cuda()\n",
    "\n",
    "# training_seq = torch.rand(8, 1, 15910) # features are normalized from 0 to 1\n",
    "\n",
    "\n",
    "# after a lot of training\n",
    "# for weights in weights_data_loader:\n",
    "#     loss = diffusion(training_seq)\n",
    "#     loss.backward()\n",
    "# sampled_seq = diffusion.sample(batch_size = 4)\n",
    "# sampled_seq.shape # (4, 32, 128)\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.Adam(diffusion.parameters(),\n",
    "#                              lr=0.004,\n",
    "#                              weight_decay=1e-8)\n",
    "\n",
    "# epochs = 1\n",
    "# outputs = []\n",
    "# losses = []\n",
    "# for epoch in range(epochs):\n",
    "#     print(\"Epoch:\", epoch)\n",
    "#     diffusion.to(device)\n",
    "#     diffusion.train()\n",
    "#     for (batch, _) in weights_data_loader:\n",
    "#         batch.to(device)\n",
    "#         loss = diffusion(batch)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "# sampled_seq = diffusion.sample(batch_size = 4)\n",
    "# sampled_seq.shape \n",
    "\n",
    "sampler = ImageSampler()\n",
    "numsampler = NumberSampler()\n",
    "\n",
    "dmmod = DiffModel()\n",
    "trainer = pl.Trainer(gpus=1, logger=logger,\n",
    "                        max_epochs=300, callbacks=[sampler],auto_lr_find=True)\n",
    "trainer.fit(dmmod, weights_data_loader)\n",
    "\n",
    "# loss = diffusion(training_images)\n",
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 18\u001b[0m\n\u001b[0;32m     10\u001b[0m diffusion \u001b[38;5;241m=\u001b[39m GaussianDiffusion1D(\n\u001b[0;32m     11\u001b[0m     model,\n\u001b[0;32m     12\u001b[0m     seq_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15910\u001b[39m,\n\u001b[0;32m     13\u001b[0m     timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m     14\u001b[0m     objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_v\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m training_seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m15910\u001b[39m) \u001b[38;5;66;03m# features are normalized from 0 to 1\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch, _) \u001b[38;5;129;01min\u001b[39;00m weights_data_loader:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\denoising_diffusion_pytorch\\denoising_diffusion_pytorch_1d.py:695\u001b[0m, in \u001b[0;36mGaussianDiffusion1D.forward\u001b[1;34m(self, img, *args, **kwargs)\u001b[0m\n\u001b[0;32m    692\u001b[0m t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps, (b,), device\u001b[39m=\u001b[39mdevice)\u001b[39m.\u001b[39mlong()\n\u001b[0;32m    694\u001b[0m img \u001b[39m=\u001b[39m normalize_to_neg_one_to_one(img)\n\u001b[1;32m--> 695\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp_losses(img, t, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\denoising_diffusion_pytorch\\denoising_diffusion_pytorch_1d.py:671\u001b[0m, in \u001b[0;36mGaussianDiffusion1D.p_losses\u001b[1;34m(self, x_start, t, noise)\u001b[0m\n\u001b[0;32m    667\u001b[0m         x_self_cond\u001b[39m.\u001b[39mdetach_()\n\u001b[0;32m    669\u001b[0m \u001b[39m# predict and take gradient step\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m model_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x, t, x_self_cond)\n\u001b[0;32m    673\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpred_noise\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    674\u001b[0m     target \u001b[39m=\u001b[39m noise\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\denoising_diffusion_pytorch\\denoising_diffusion_pytorch_1d.py:360\u001b[0m, in \u001b[0;36mUnet1D.forward\u001b[1;34m(self, x, time, x_self_cond)\u001b[0m\n\u001b[0;32m    356\u001b[0m     h\u001b[39m.\u001b[39mappend(x)\n\u001b[0;32m    358\u001b[0m     x \u001b[39m=\u001b[39m downsample(x)\n\u001b[1;32m--> 360\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmid_block1(x, t)\n\u001b[0;32m    361\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmid_attn(x)\n\u001b[0;32m    362\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmid_block2(x, t)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\denoising_diffusion_pytorch\\denoising_diffusion_pytorch_1d.py:189\u001b[0m, in \u001b[0;36mResnetBlock.forward\u001b[1;34m(self, x, time_emb)\u001b[0m\n\u001b[0;32m    186\u001b[0m     time_emb \u001b[39m=\u001b[39m rearrange(time_emb, \u001b[39m'\u001b[39m\u001b[39mb c -> b c 1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    187\u001b[0m     scale_shift \u001b[39m=\u001b[39m time_emb\u001b[39m.\u001b[39mchunk(\u001b[39m2\u001b[39m, dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m--> 189\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock1(x, scale_shift \u001b[39m=\u001b[39;49m scale_shift)\n\u001b[0;32m    191\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock2(h)\n\u001b[0;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m h \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_conv(x)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\denoising_diffusion_pytorch\\denoising_diffusion_pytorch_1d.py:159\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x, scale_shift)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, scale_shift \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 159\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproj(x)\n\u001b[0;32m    160\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(x)\n\u001b[0;32m    162\u001b[0m     \u001b[39mif\u001b[39;00m exists(scale_shift):\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Desktop\\Math522\\FinalProject\\VAE\\lib\\site-packages\\denoising_diffusion_pytorch\\denoising_diffusion_pytorch_1d.py:93\u001b[0m, in \u001b[0;36mWeightStandardizedConv2d.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     90\u001b[0m var \u001b[39m=\u001b[39m reduce(weight, \u001b[39m'\u001b[39m\u001b[39mo ... -> o 1 1\u001b[39m\u001b[39m'\u001b[39m, partial(torch\u001b[39m.\u001b[39mvar, unbiased \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m))\n\u001b[0;32m     91\u001b[0m normalized_weight \u001b[39m=\u001b[39m (weight \u001b[39m-\u001b[39m mean) \u001b[39m*\u001b[39m (var \u001b[39m+\u001b[39m eps)\u001b[39m.\u001b[39mrsqrt()\n\u001b[1;32m---> 93\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(x, normalized_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from denoising_diffusion_pytorch import Unet1D, GaussianDiffusion1D\n",
    "\n",
    "model = Unet1D(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    channels = 1\n",
    ")\n",
    "\n",
    "diffusion = GaussianDiffusion1D(\n",
    "    model,\n",
    "    seq_length = 15910,\n",
    "    timesteps = 1000,\n",
    "    objective = 'pred_v'\n",
    ")\n",
    "\n",
    "training_seq = torch.rand(8, 1, 15910) # features are normalized from 0 to 1\n",
    "loss = diffusion(training_seq)\n",
    "loss.backward()\n",
    "for (batch, _) in weights_data_loader:\n",
    "    print(batch.shape)\n",
    "    batch = batch.reshape(20,1,15910)\n",
    "    batch.to(device)\n",
    "    loss = diffusion(batch)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "# after a lot of training\n",
    "\n",
    "sampled_seq = diffusion.sample(batch_size = 4)\n",
    "sampled_seq.shape # (4, 32, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('VAE': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc8ca14c0d6c65d65460967eac9c47a87cbaa09f2e18c207b78e97d2c8db187b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
